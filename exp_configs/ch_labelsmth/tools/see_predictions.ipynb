{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa2f0eca-a939-4a0c-9330-5216f09b5a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import torch\n",
    "import exp_configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "99e7217a-4985-4daf-bbd7-1b3e79ddcfdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "\n",
    "#entity = 'cnn'\n",
    "#project = 'multilabel_ar_hmdb_202207'\n",
    "entity = 'kiyoon'\n",
    "project = 'multilabel_ar_feature_20220519'\n",
    "api = wandb.Api()\n",
    "\n",
    "runs = api.runs(f\"{entity}/{project}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6480dd17-4396-48cf-9c3d-e3c5fbc46156",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epic100_verb_features ch_beta.featuremodel concat_RGB_flow_assume_negative seed13 v0 1vtg2xlm\n",
      "predictions:v0\n"
     ]
    }
   ],
   "source": [
    "# find the run\n",
    "\n",
    "#dataset = 'confusing_hmdb_102_features'\n",
    "dataset = 'epic100_verb_features'\n",
    "loss = 'concat_RGB_flow_assume_negative'\n",
    "#loss = 'concat_RGB_flow_entropy_maximise'\n",
    "#split = 3\n",
    "seed = 13\n",
    "#search_run_names = [f'{dataset} ch_beta.featuremodel {loss} split{split}']\n",
    "search_run_names = [f'{dataset} ch_beta.featuremodel {loss} seed{seed}']\n",
    "#search_run_names = ['hmdb_confusion2 tsm_resnet50_nopartialbn entropy_maximise split3', 'hmdb_confusion2 ch_epic100.tsm_resnet50_flow entropy_maximise split3']\n",
    "found_runs = []\n",
    "for run in runs:\n",
    "    for search_run_name in search_run_names:\n",
    "        if search_run_name in run.name:\n",
    "            print(run.name, run.id)\n",
    "            found_runs.append(run)\n",
    "\n",
    "assert len(found_runs) == len(search_run_names), f'{len(found_runs) = }'\n",
    "\n",
    "predictions = []\n",
    "for run in found_runs:\n",
    "    # find artifact from the run.\n",
    "    produced_artifacts = run.logged_artifacts()\n",
    "    artifact_name = None\n",
    "    for art in produced_artifacts:\n",
    "        if art.name.startswith('predictions'):\n",
    "            print(art.name)\n",
    "            artifact_name = art.name\n",
    "\n",
    "    # Download the artifact\n",
    "    artifact = api.artifact(f\"{entity}/{project}/{artifact_name}\")\n",
    "    artifact_dir = artifact.checkout()\n",
    "\n",
    "    # open\n",
    "    best_epoch = run.summary['epoch_best-val_epoch']\n",
    "    with open(os.path.join(artifact_dir, f'epoch_{best_epoch:04d}_val_oneclip.pkl'), 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    predictions.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "28e57abc-8e0a-4f9c-88f9-bcd2e6076a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute sigmoid average of two predictions\n",
    "sigmoid_1 = torch.sigmoid(torch.tensor(predictions[0]['video_predictions']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2c77a8cc-5106-48bd-8f06-3a57484b0d61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5025)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigmoid_1.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "c5ff22ef-3651-4d9a-b452-86f451c8de46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[9.5276e-01, 1.0402e-05, 6.3911e-06,  ..., 5.7971e-06, 1.1700e-06,\n",
       "         1.5672e-03],\n",
       "        [9.8327e-01, 6.8464e-07, 5.9809e-06,  ..., 2.3575e-07, 1.8863e-08,\n",
       "         2.9382e-03],\n",
       "        [9.7815e-01, 4.8019e-06, 1.2909e-05,  ..., 7.8160e-06, 2.1755e-05,\n",
       "         5.8592e-04],\n",
       "        ...,\n",
       "        [1.0262e-03, 1.1863e-05, 2.2659e-03,  ..., 3.1138e-03, 1.6888e-04,\n",
       "         3.6149e-02],\n",
       "        [6.4585e-06, 9.8888e-07, 5.7388e-04,  ..., 5.4901e-03, 2.3314e-05,\n",
       "         4.9621e-02],\n",
       "        [1.6512e-02, 1.2595e-07, 2.4703e-05,  ..., 2.2985e-03, 6.0593e-05,\n",
       "         6.6771e-03]])"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigmoid_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "bdd23739-17dc-4a3f-bce8-a940ebc9bab6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9597, 0.2314, 0.2342,  ..., 0.2464, 0.2348, 0.2751],\n",
       "        [0.9812, 0.2367, 0.2396,  ..., 0.2586, 0.2454, 0.2983],\n",
       "        [0.9697, 0.2401, 0.2405,  ..., 0.2787, 0.2597, 0.2798],\n",
       "        ...,\n",
       "        [0.2622, 0.2284, 0.2572,  ..., 0.3235, 0.3317, 0.2760],\n",
       "        [0.2211, 0.2351, 0.2625,  ..., 0.2832, 0.2446, 0.3065],\n",
       "        [0.3411, 0.2631, 0.2853,  ..., 0.2343, 0.2441, 0.2975]])"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigmoid_average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "f78e748c-7514-4604-9e05-52cd4c1a2758",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<pyvideoai.metrics.multilabel_accuracy.ClipMultilabelAccuracyMetric object at 0x7f4f9b164af0>, <pyvideoai.metrics.top1_multilabel_accuracy.ClipTop1MultilabelAccuracyMetric object at 0x7f4f9b164760>, <pyvideoai.metrics.top1_multilabel_accuracy.ClipTopkMultilabelAccuracyMetric object at 0x7f4f9b164730>, <pyvideoai.metrics.mAP.Clip_mAPMetric object at 0x7f4f9b164700>]\n",
      "0.592156862745098\n",
      "0.6104575163398693\n",
      "0.6928104575163399\n",
      "0.6187192633711707\n"
     ]
    }
   ],
   "source": [
    "# calculate metrics\n",
    "cfg = exp_configs.load_cfg('hmdb_confusion2', 'tsm_resnet50_nopartialbn', 'assume_negative', dataset_channel='beta', exp_channel='labelsmth')\n",
    "print(cfg.metrics['val'])\n",
    "for metric in cfg.metrics['val']:\n",
    "    metric.clean_data()\n",
    "    metric.add_clip_predictions(torch.tensor(predictions[0]['video_ids']), sigmoid_average, torch.tensor(predictions[0]['video_labels']))\n",
    "    metric.calculate_metrics()\n",
    "    print(metric.last_calculated_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b35f10-26c7-490e-9be0-b4451e287292",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
